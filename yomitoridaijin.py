import streamlit as st
import re
import pandas as pd
from datetime import datetime, timedelta, timezone

# --- 1. å®šæ•°ã¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° ---

# æ—¥æœ¬æ¨™æº–æ™‚ (JST) ã®ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ (UTC+9)
JST = timezone(timedelta(hours=9), 'JST')

def clean_time_string_for_parsing(time_str):
    """
    OCRèª¤èªè­˜ã‚’ä¿®æ­£ã—ã€datetime.strptimeã§ãƒ‘ãƒ¼ã‚¹å¯èƒ½ãª
    æ¨™æº–å½¢å¼ (YYYY-MM-DDTHH:MM:SS) ã«æ•´å½¢ã™ã‚‹
    ã€ãƒ‘ãƒ¼ã‚¹ç”¨ã€‘: Zã‚„ãƒŸãƒªç§’ã¯å«ã¾ãªã„
    """
    
    # 1. l/I -> 1 ã®ç½®æ›ï¼ˆll -> 11 ã¸ã®å¯¾å¿œï¼‰
    cleaned = time_str.replace('l', '1').replace('I', '1')
    
    # 2. ä½™åˆ†ãªãƒã‚¤ã‚ºæ–‡å­—ã‚’å‰Šé™¤
    cleaned = cleaned.replace("'", "").replace("b", "").replace(">", "").replace("`", "")

    # 3. æ—¥ä»˜ã¨æ™‚åˆ»ã‚’å³å¯†ãªæ­£è¦è¡¨ç¾ã§æŠ½å‡º
    date_pattern = re.search(r'(\d{4}[-]\d{2}[-]\d{2})', cleaned)
    time_pattern = re.search(r'(\d{2}[:]\d{2}[:]\d{2})', cleaned)
    
    if date_pattern and time_pattern:
        date_part = date_pattern.group(1)
        time_part = time_pattern.group(1)
        
        # 4. æ¨™æº–å½¢å¼ YYYY-MM-DDTHH:MM:SS ã§å†æ§‹ç¯‰
        return f"{date_part}T{time_part}"
    else:
        return ""

def clean_time_string_for_display(time_str):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¦–èªã™ã‚‹ãŸã‚ã®ã‚¯ãƒªãƒ¼ãƒ³æ¸ˆã¿UTCæ–‡å­—åˆ— (YYYY-MM-DDTHH:MM:SS.000Z) ã‚’ç”Ÿæˆã™ã‚‹
    ã€è¡¨ç¤ºç”¨ã€‘: .000Z ã‚’ä»˜ä¸
    """
    parsed_str = clean_time_string_for_parsing(time_str)
    
    if parsed_str:
        return f"{parsed_str}.000Z"
    return "**[æŠ½å‡ºå¤±æ•—]**"


def convert_utc_to_jst(utc_datetime_str):
    """
    UTCæ™‚åˆ»æ–‡å­—åˆ—ã‚’JSTã«å¤‰æ›ã—ã€'YYYY-MM-DD HH:MM:SS'å½¢å¼ã§è¿”ã™
    """
    cleaned_time_str = clean_time_string_for_parsing(utc_datetime_str)
    
    if not cleaned_time_str:
        return "**[ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ - æŠ½å‡ºå¤±æ•—]**"

    try:
        dt_obj_utc_naive = datetime.strptime(
            cleaned_time_str,
            '%Y-%m-%dT%H:%M:%S'
        )
        
        dt_obj_utc = dt_obj_utc_naive.replace(tzinfo=timezone.utc)
        dt_obj_jst = dt_obj_utc.astimezone(JST)
        
        return dt_obj_jst.strftime('%Y-%m-%d %H:%M:%S')
    except ValueError as e:
        return f"**[ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ - å½¢å¼ä¸æ­£]** (ã‚¯ãƒªãƒ¼ãƒ³å¾Œ: {cleaned_time_str}, ã‚¨ãƒ©ãƒ¼: {e})"

def extract_ip_audit_data_final(raw_text):
    """
    OCRãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰createdAtã¨loginIpã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã€ãƒšã‚¢ã«ã—ã¦DataFrameã‚’è¿”ã™
    """
    ip_address_pattern = re.compile(r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})')
    all_login_ip = ip_address_pattern.findall(raw_text)

    createdAt_pattern = re.compile(r'"(created|cneated)At"\s*:\s*"([^"]+)"')
    all_created_at = [match[1] for match in createdAt_pattern.findall(raw_text)]
    
    st.info(f"æŠ½å‡ºã•ã‚ŒãŸUTCæ™‚åˆ»ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: **{len(all_created_at)}**")
    st.info(f"æŠ½å‡ºã•ã‚ŒãŸIPã‚¢ãƒ‰ãƒ¬ã‚¹ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: **{len(all_login_ip)}**")

    results = []
    max_len = max(len(all_created_at), len(all_login_ip))
    
    for i in range(max_len):
        
        if i < len(all_created_at):
            utc_time_raw = all_created_at[i].strip()
        else:
            utc_time_raw = "**(æ™‚åˆ»æŠ½å‡ºå¤±æ•—/ãƒ¬ã‚³ãƒ¼ãƒ‰ãªã—)**"

        if i < len(all_login_ip):
            ip_address = all_login_ip[i].strip()
        else:
            ip_address = "**(IPæŠ½å‡ºå¤±æ•—/ãƒ¬ã‚³ãƒ¼ãƒ‰ãªã—)**" 
        
        results.append({
            'UTC (å…ƒãƒ‡ãƒ¼ã‚¿)': utc_time_raw,
            'UTC (ã‚¯ãƒªãƒ¼ãƒ³æ¸ˆ)': clean_time_string_for_display(utc_time_raw),
            'JST (UTC + 9æ™‚é–“)': convert_utc_to_jst(utc_time_raw),
            'IPã‚¢ãƒ‰ãƒ¬ã‚¹ (loginIp)': ip_address
        })

    return pd.DataFrame(results)

# --- 2. Streamlit UIå®šç¾© ---

st.title("ğŸ«… èª­å–å¤§è‡£ï¼ˆä»®ï¼‰")
st.markdown("å‹•ä½œç¢ºèªç”¨ã®ãƒ†ã‚¹ãƒˆç‰ˆã‚’ä½œæˆã—ã¾ã—ãŸã€‚")
st.markdown("createdAtã®ã‚­ãƒ¼åèª¤èªè­˜ï¼ˆcneatedAtï¼‰ã«ã‚‚å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚")
st.markdown("IPã‚¢ãƒ‰ãƒ¬ã‚¹ã®æŠ½å‡ºã¯ã€3ã¤ã®ã€Œ.ã€ã§åŒºåˆ‡ã‚‰ã‚ŒãŸ4ã¤ã®æ•°å€¤ã®çµ„ã¿åˆã‚ã›ã‚’æŠ½å‡ºã—ã¾ã™ã€‚IPv6ã«ã¯å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚")
st.markdown("createdAtã®æ–‡å­—ã‚„IPã‚¢ãƒ‰ãƒ¬ã‚¹ã®æ•°å­—ãŒã»ã‹ã®æ–‡å­—ã«èª¤èªè­˜ã•ã‚ŒãŸå ´åˆã¯ã€ãã®æ–‡å­—ã‚‚åæ˜ ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã®ã§æ•™ãˆã¦ãã ã•ã„ï¼")
st.markdown("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€ã“ã®ã‚¢ãƒ—ãƒªå†…ã§å‡¦ç†ãƒ»å®Œçµã—ã¾ã™ã€‚ãªã®ã§ã€æƒ…å ±æ¼ãˆã„ã®å¿ƒé…ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å¿ƒé…ã®æ–¹ã¯GitHubã‹ã‚‰Pythonã‚³ãƒ¼ãƒ‰ã‚’è¦‹ã¦åˆ¤æ–­ã—ã¦ãã ã•ã„!")
st.markdown("---")
st.markdown("### èª­å–é©å‘½ã®ã‚¹ã‚­ãƒ£ãƒ³ã®ã‚³ãƒ„ã¨ã‚„ã‚Šæ–¹")
st.markdown("- ã‚¨ã‚¯ã‚»ãƒ¬ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã§ã‚¹ã‚­ãƒ£ãƒ³ã™ã‚‹ã€‚")
st.markdown("- è‹±èªãƒ¢ãƒ¼ãƒ‰ã«è¨­å®šã™ã‚‹ï¼ˆã©ã£ã¡ã‹å¿˜ã‚Œã¾ã—ãŸã‘ã©ã€ã‚¢ãƒ¡ãƒªã‚«ã‹ã‚¤ã‚®ãƒªã‚¹ã®å›½æ——ã®ãƒãƒ¼ã‚¯ã ã£ãŸã¨æ€ã„ã¾ã™ã€‚)")
st.markdown("- PDFã®ãƒšãƒ¼ã‚¸å…¨ä½“ã‚’å››è§’ã§å›²ã£ã¦æŠ½å‡ºç¯„å›²ã®é¸æŠã‚’ã™ã‚‹ã€‚ï¼ˆãŸã ã—ã€ä½™è¨ˆãªä¸Šã®éƒ¨åˆ†ã‚„ä¸‹ã®ãƒšãƒ¼ã‚¸ç•ªå·ã€PGP SIGNATUREãªã©ã®æš—å·éƒ¨åˆ†ã¯é¸æŠã—ãªã„ã€‚ï¼‰")
st.markdown("- ä¸€å¤ªéƒã®ã‚¢ã‚¤ã‚³ãƒ³ã‹ã‚‰txtå½¢å¼ã§ä¿å­˜ã™ã‚‹ã€‚")
st.markdown("- ä¿å­˜ã—ãŸtxtãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã“ã®ã‚¢ãƒ—ãƒªã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚")
st.markdown("---")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ
uploaded_file = st.file_uploader(
    "ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ« (ä¾‹ï¼šyomikaku.txt) ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", 
    type=['txt']
)

if uploaded_file is not None:
    try:
        raw_text = uploaded_file.read().decode('utf-8')
        st.success(f"ãƒ•ã‚¡ã‚¤ãƒ«å: **{uploaded_file.name}** ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
        
        # å‡¦ç†å®Ÿè¡Œ
        df_result = extract_ip_audit_data_final(raw_text)
        
        st.header("âœ… æŠ½å‡ºãƒ»å¤‰æ›çµæœ")
        
        if not df_result.empty:
            if df_result['JST (UTC + 9æ™‚é–“)'].str.contains('ã‚¨ãƒ©ãƒ¼').any():
                st.warning("ä¸€éƒ¨ã®æ™‚åˆ»ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            
            # é€£ç•ª(ç•ªå·)åˆ—ã‚’æ–°è¨­ã—ã€ä¸€ç•ªå·¦ã«ç§»å‹•ã•ã›ã‚‹
            df_result.insert(0, 'ç•ªå·', range(1, 1 + len(df_result)))
            
            # Streamlitè¡¨ç¤ºç”¨ã®DataFrameã‚’æº–å‚™ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®é€£ç•ªåŒ–ã¯è¡Œã‚ãªã„ï¼‰
            st.dataframe(
                df_result,
                use_container_width=True,
                # Streamlitã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆè¬ã®åˆ—ï¼‰ã¯è¡¨ç¤ºã•ã›ãªã„
                hide_index=True 
            )

            # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            @st.cache_data
            def convert_df_to_csv(df):
                # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¯CP932ï¼ˆShift-JISï¼‰ã‚’ç¶­æŒã€ç•ªå·åˆ—ãŒã‚ã‚‹ã®ã§ index=False ã§OK
                return df.to_csv(index=False, encoding='cp932').encode('cp932')
            
            csv = convert_df_to_csv(df_result)
            st.download_button(
                label="ğŸ“¥ çµæœã‚’CSVã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv,
                file_name='yomidai.csv',
                mime='text/csv',
            )
            
        else:
            st.error("ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

    except Exception as e:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
